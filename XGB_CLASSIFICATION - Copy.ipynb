{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score,recall_score,precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "import matplotlib.pylab as plt\n",
    "from collections import Counter\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from xgboost import plot_tree\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from inspect import signature\n",
    "import shap\n",
    "import scikitplot as skplt\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "import math as m\n",
    "import time\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  {'base_score': 0.17,\n",
    "            'booster': 'gbtree',\n",
    "            'colsample_bylevel': 1,\n",
    "            'colsample_bynode': 1,\n",
    "            'colsample_bytree': 1,\n",
    "            'gamma': 0,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_delta_step': 0,\n",
    "            'max_depth': 8,\n",
    "            'min_child_weight': 1,\n",
    "            'missing': None,\n",
    "            'n_estimators': 150,\n",
    "            'n_jobs': -1,\n",
    "            'objective': 'binary:logistic',\n",
    "            'random_state': 0,\n",
    "            'reg_alpha': 0.5,\n",
    "            'reg_lambda': 50,\n",
    "            'scale_pos_weight': 5,\n",
    "            'seed': 7,\n",
    "            'silent': True,\n",
    "            'subsample': 1,\n",
    "            'verbosity': 1,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xgb_cv(X,y, params, n_estimators=150, folds=5, metric='error', verbose=30, cv=True, test_size=0.3):\n",
    "    start_time = time.time()\n",
    "    features = X.columns\n",
    "    params['n_estimators'] = n_estimators\n",
    "    estimators = []\n",
    "    total_progress = []\n",
    "    if cv:\n",
    "        kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "        params['eval_metric'] = metric\n",
    "        i = 0\n",
    "        print(f'Num of splits: {folds}\\nX_train size: {int(X.shape[0]*(folds-1)/folds)} ----- X_test size: {int(X.shape[0]/folds)}\\n')\n",
    "        for nfold, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "            progress={}\n",
    "            X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "            y_train, y_test = y.iloc[train_index].values.ravel(), y.iloc[test_index].values.ravel()\n",
    "            \n",
    "            xgtrain = xgb.DMatrix(X_train, label=y_train, feature_names = features)\n",
    "            xgeval = xgb.DMatrix(X_test, label=y_test, feature_names = features)\n",
    "            gbm = xgb.train(params, xgtrain, evals=[(xgtrain,'train'), (xgeval,'eval')],evals_result = progress, verbose_eval = verbose, num_boost_round = n_estimators)\n",
    "            #model.fit(X_train, y_train, eval_metric=metric)\n",
    "            estimators.append(gbm)\n",
    "            total_progress.append(progress)\n",
    "            print(f'{nfold+1} of {folds} is processed')\n",
    "        \n",
    "        #eval_results\n",
    "        train_eval = np.array(total_progress[0]['train'][metric])\n",
    "        test_eval = np.array(total_progress[0]['eval'][metric])\n",
    "        for i in range(1,5):\n",
    "            train_eval += np.array(total_progress[i]['train'][metric])\n",
    "            test_eval += np.array(total_progress[i]['eval'][metric])\n",
    "        train_eval = train_eval/folds\n",
    "        test_eval = test_eval/folds\n",
    "        total_progress = [train_eval, test_eval]\n",
    "    \n",
    "    else:\n",
    "        gbm = XGBClassifier()\n",
    "        gbm.set_params(**params)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "        print(f'X_train size: {X_train.shape[0]} ----- X_test size: {X_test.shape[0]}\\n')\n",
    "        gbm.fit(X_train, y_train,eval_metric=metric, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=verbose)\n",
    "        estimators.append(gbm)\n",
    "        total_progress = [gbm.evals_result_['validation_0'][metric], gbm.evals_result_['validation_1'][metric]]\n",
    "    print(\"\\n--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return estimators, total_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_calc(alg, X, y, recall=0.9, lim=0.0001, cv=False, to_print=False, auc=False): #returns (precision, threshold)\n",
    "    lst = []\n",
    "    for model in alg:\n",
    "        y_predict_proba = model.predict(xgb.DMatrix(X)) if cv else model.predict_proba(X)[:,1]\n",
    "        first, last, ix = 0.1, 0.5, 0.1\n",
    "        rec_temp = recall_score(y,  np.where(y_predict_proba<ix,0,1))\n",
    "        \n",
    "        while abs(recall-rec_temp)>lim:\n",
    "            ix = (first+last)/2\n",
    "            rec_temp = recall_score(y,  np.where(y_predict_proba<ix,0,1))\n",
    "            if recall>rec_temp:\n",
    "                last = ix\n",
    "            elif rec_temp>recall:\n",
    "                first = ix\n",
    "        \n",
    "        lst.append([precision_score(y, np.where(y_predict_proba<ix,0,1)), ix])\n",
    "    lst = np.array(lst).mean(0)\n",
    "    if to_print:\n",
    "        print(f'precision = {np.round(lst[0],5)} -- (recall = {recall}, th = {np.round(lst[1],5)})')\n",
    "    return lst[0], lst[1], np.where(y_predict_proba<ix,0,1)\n",
    "    \n",
    "    #precision_calc(l2, df.drop(todrop,1), df['Target'], 0.9, 0.0001, cv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"with open('C:/Users/ivanov.al/Desktop/Projects/purchasing-behavior-model-master/out/data_train_test_val.csv', 'rb') as f:\n",
    "    df = pd.read_csv(f, sep=',')\n",
    "with open('../out/data_predict.csv','rb') as f:\n",
    "    df_pred = pd.read_csv(f)\"\"\"\n",
    "with open('C:/Users/ivanov.al/Desktop/Projects/purchasing-behavior-model-master/4SASHA/customers_variables/df_ready_shifted.csv', 'rb') as f:\n",
    "          df_shifted = pd.read_csv(f, sep=',')\n",
    "with open('C:/Users/ivanov.al/Desktop/Projects/purchasing-behavior-model-master/4SASHA/customers_variables/df_ready.csv', 'rb') as f:\n",
    "          df = pd.read_csv(f, sep=',')\n",
    "df = df[~df.GUID.str.contains('_t')]\n",
    "#df_shifted = df_shifted[~df_shifted.GUID.str.contains('_t3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Monetary value mean', 'Monetary value sum','TOT_ALL','TOT_NOTE', 'previous t_1 Galaxy S',\n",
    "       'previous t_2 Galaxy S', 'previous t_3 Galaxy S',\n",
    "       'previous t_4 Galaxy S', 'previous t_5 Galaxy S', 'Tot_Galaxy',\n",
    "       'TOT_OTHER', 'abandon_note_t_4', 'abandon_note_t_3', 'abandon_note_t_2',\n",
    "       'abandon_note_t_1', 'abandon_note', 'back_to_NOTE_t_3',\n",
    "       'back_to_NOTE_t_2', 'back_to_NOTE_t_1', 'back_to_NOTE_NUM',\n",
    "       'abandon_note_NUM', 'back_to_NOTE','Recency DEVICE', 'no purchase device_2 t_1_2', 'Recency_from_now',\n",
    "       'Recency DEVICE_T_MIN_T_1', 'Recency DEVICE_T_MIN_today',\n",
    "       'Recency_DEVICE_avg', 'Recency NOTE', 'no purchase Note',\n",
    "       'Currently using device','S Health', 'S Pay', 'Samsung Members','Segment code','Usage period', 'Year lapsed',\n",
    "       'Gender', 'No longer contact', 'Samsung Deleted', 'long_commun', 'age','no purchase device_2 t_1_3', 'TOT_NOTE_gr_1', 'TOT_ALL_gr_1', 'TOT_OTHER_gr_1', 'Tot_Galaxy_gr1',           'TOT_NOTE_gr_2', 'TOT_ALL_gr_2', 'TOT_OTHER_gr_2', 'Tot_Galaxy_gr_2', 'TOT_NOTE_gr_3', 'TOT_ALL_gr_3', 'TOT_OTHER_gr_3', 'Tot_Galaxy_gr_3', 'age1', 'Recency NOTE1',                'Recency NOTE1_gr', 'Recency NOTE1_gr2','Target']\n",
    "#features = list(set(features) - set(['back_to_NOTE', 'Samsung Deleted', 'no purchase device_2 t_1_2', 'no purchase Note', 'back_to_NOTE_t_3', 'back_to_NOTE_t_1', \n",
    "#                                     'previous t_4 Galaxy S', 'abandon_note_NUM', 'abandon_note_t_4']))\n",
    "\n",
    "df_shifted[['S Health','S Pay','Samsung Members','Segment code']] = df_shifted[['S Health','S Pay','Samsung Members','Segment code']].replace('55000', np.nan)\n",
    "df_shifted[['S Health','S Pay','Samsung Members','Segment code']] = df_shifted[['S Health','S Pay','Samsung Members','Segment code']].fillna('N')\n",
    "df[['S Health','S Pay','Samsung Members','Segment code']] = df[['S Health','S Pay','Samsung Members','Segment code']].replace('55000', np.nan)\n",
    "df[['S Health','S Pay','Samsung Members','Segment code']] = df[['S Health','S Pay','Samsung Members','Segment code']].fillna('N')\n",
    "\n",
    "\n",
    "dict_object_cols1 = {}\n",
    "for col in['S Health','S Pay','Samsung Members','Segment code']:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_shifted[col])\n",
    "    df_shifted[col] = le.transform(df_shifted[col])\n",
    "    df[col] = le.transform(df[col])\n",
    "    dict_object_cols1[col] = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "df_shifted = df_shifted[features]\n",
    "\n",
    "df_guids = df['GUID'].values\n",
    "df = df[features]\n",
    "\n",
    "features.remove('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.20261 -- (recall = 0.9, th = 0.19969)\n"
     ]
    }
   ],
   "source": [
    "#l2, evals2 = xgb_cv(df_shifted.drop('Target',1), df_shifted['Target'], params,n_estimators=50, cv = True, verbose=False)\n",
    "score = precision_calc(l2, df.drop('Target',1), df['Target'], 0.9, 0.0001, cv=True, to_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GUID</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0064xfpxlz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006tazj5sh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0070lirtjq</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>009zjirxth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00a9vcanrf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94083</th>\n",
       "      <td>zzyzvpppsj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94084</th>\n",
       "      <td>zzz5fobgxh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94085</th>\n",
       "      <td>zzzd7mzxcj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94086</th>\n",
       "      <td>zzzfhwbzah</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94087</th>\n",
       "      <td>zzzwdke1mc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94088 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             GUID Purchase\n",
       "0      0064xfpxlz        1\n",
       "1      006tazj5sh        1\n",
       "2      0070lirtjq        1\n",
       "3      009zjirxth        0\n",
       "4      00a9vcanrf        1\n",
       "...           ...      ...\n",
       "94083  zzyzvpppsj        1\n",
       "94084  zzz5fobgxh        1\n",
       "94085  zzzd7mzxcj        1\n",
       "94086  zzzfhwbzah        0\n",
       "94087  zzzwdke1mc        1\n",
       "\n",
       "[94088 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.stack([df_guids, score[2]]).T, columns=['GUID', 'Purchase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1272px",
    "left": "126px",
    "top": "109.333px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
